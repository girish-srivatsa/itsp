{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Emotify_ITSP.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/girish-srivatsa/itsp/blob/master/google%20colab/Emotify_ITSP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPV6qtjVlzun",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0aadfdf8-01cc-4523-aa99-0f06001f5cbc"
      },
      "source": [
        "# Import all required packages.\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import keras \n",
        "from keras import layers\n",
        "from keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv1D, Conv2D\n",
        "from keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2D\n",
        "from keras.layers import Dropout \n",
        "from keras.models import Model\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import os\n",
        "from PIL import Image\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8hGAC-AnRsR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import modules for accessing files in drive.\n",
        "\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHlKYlminV41",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Here, I authenticate my google account.\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4IovBtG533hM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# the url links for the dataset in my drive.\n",
        "\n",
        "url = \"https://drive.google.com/file/d/1tiAwX-8t4XKIVKhN49Vh6H9dVFVQzT5E/view?usp=sharing\"\n",
        "url_id = url[32 : 65]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-t7xbDznd2V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Download the dataset.\n",
        "\n",
        "downloaded = drive.CreateFile({'id' : url_id})\n",
        "downloaded.GetContentFile('Final_dataset.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KmPKA75i4EKZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "e30c4841-992e-4eab-f18a-f439f561523f"
      },
      "source": [
        "# Extract the dataset as a dataframe using pandas library.\n",
        "\n",
        "data = pd.read_csv('Final_dataset.csv')\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>emotion</th>\n",
              "      <th>pixels</th>\n",
              "      <th>Usage</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4</td>\n",
              "      <td>243 243 243 243 243 243 243 243 245 243 243 24...</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>189 189 189 187 187 187 191 191 191 189 189 18...</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6</td>\n",
              "      <td>200 196 195 197 197 195 197 197 195 198 197 19...</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   emotion                                             pixels     Usage\n",
              "0        4  243 243 243 243 243 243 243 243 245 243 243 24...  Training\n",
              "1        0  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...  Training\n",
              "2        0  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...  Training\n",
              "3        4  189 189 189 187 187 187 191 191 191 189 189 18...  Training\n",
              "4        6  200 196 195 197 197 195 197 197 195 198 197 19...  Training"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wsMGIuO2upJg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert the space seperated pixels into lists.\n",
        "\n",
        "for i in range(data.shape[0]):\n",
        "  pix_list = [float(x) for x in data['pixels'][i].split(' ')]\n",
        "  # pix_list = norm_list(pix_list)\n",
        "  pix_arr = np.array(pix_list)\n",
        "  pix_img = np.reshape(pix_arr, (48, 48))\n",
        "  pix_img_to_list = pix_img.tolist()\n",
        "  data['pixels'][i] = pix_img_to_list\n",
        "\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNEsClrgodPC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "outputId": "f5e5237c-8625-4077-ab16-3580782bf5ac"
      },
      "source": [
        "# Make new dataframes for train, dev and test.\n",
        "\n",
        "dftrain = data[data['Usage'] == 'Training']\n",
        "dfdev = data[data['Usage'] == 'PublicTest']\n",
        "dftest = data[data['Usage'] == 'PrivateTest']\n",
        "print(dftrain.shape, dfdev.shape, dftest.shape)\n",
        "\n",
        "dftrain.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(30694, 3) (4089, 3) (4122, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>emotion</th>\n",
              "      <th>pixels</th>\n",
              "      <th>Usage</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>[[86.0, 104.0, 151.0, 119.0, 35.0, 26.0, 36.0,...</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>[[30.0, 30.0, 28.0, 30.0, 27.0, 23.0, 11.0, 5....</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>[[226.0, 226.0, 225.0, 223.0, 223.0, 216.0, 21...</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>[[180.0, 133.0, 85.0, 75.0, 63.0, 63.0, 66.0, ...</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>[[14.0, 15.0, 32.0, 72.0, 82.0, 113.0, 180.0, ...</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   emotion                                             pixels     Usage\n",
              "0        0  [[86.0, 104.0, 151.0, 119.0, 35.0, 26.0, 36.0,...  Training\n",
              "1        4  [[30.0, 30.0, 28.0, 30.0, 27.0, 23.0, 11.0, 5....  Training\n",
              "2        3  [[226.0, 226.0, 225.0, 223.0, 223.0, 216.0, 21...  Training\n",
              "3        4  [[180.0, 133.0, 85.0, 75.0, 63.0, 63.0, 66.0, ...  Training\n",
              "4        0  [[14.0, 15.0, 32.0, 72.0, 82.0, 113.0, 180.0, ...  Training"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYyMG_F7opIj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "1cc68f0f-9beb-4c42-943e-8ed11783f1bc"
      },
      "source": [
        "# Look at the distribution of the emotions in the dataframes.\n",
        "\n",
        "print(dftrain.emotion.hist(bins = 20))\n",
        "# print(dfdev.emotion.hist(bins = 20))\n",
        "# print(dftest.emotion.hist(bins = 20))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AxesSubplot(0.125,0.125;0.775x0.755)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9BsAuxoubhO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Count of elements in various dataframes.\n",
        "\n",
        "train_count = dftrain.shape[0]\n",
        "dev_count = dfdev.shape[0]\n",
        "test_count = dftest.shape[0]\n",
        "img_h = 48\n",
        "img_w = 48"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0cKGG99Q9FxZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Emotion classes.\n",
        "\n",
        "y_classes = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SH_rqWBrsnbJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert y arrays to one hot matrices.\n",
        "\n",
        "y_train = np.array(dftrain['emotion'])\n",
        "y_dev = np.array(dfdev['emotion'])\n",
        "y_test = np.array(dftest['emotion'])\n",
        "\n",
        "Y_train = tf.keras.utils.to_categorical(y_train, num_classes = 7)\n",
        "Y_dev = tf.keras.utils.to_categorical(y_dev, num_classes = 7)\n",
        "Y_test = tf.keras.utils.to_categorical(y_test, num_classes = 7)\n",
        "\n",
        "# print(Y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g93ZOJme1TCy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function to extract the numpy array of images from the dataframe.\n",
        "\n",
        "def get_X(df, start, end):\n",
        "  x_list = []\n",
        "  for i in range(start, end):\n",
        "    x_list.append(df[\"pixels\"][i])\n",
        "  X = np.array(x_list)\n",
        "  # X = np.stack([arr] * 3, axis = -1)\n",
        "  X = X / 255\n",
        "  return X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nap4G4vXuCoT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "50692f69-3a86-415d-dd16-b86213ba84de"
      },
      "source": [
        "# Extract data using the above get_X() function.\n",
        "\n",
        "X_train = get_X(dftrain, 0, train_count)\n",
        "X_dev = get_X(dfdev, train_count, train_count + dev_count)\n",
        "X_test = get_X(dftest, train_count + dev_count, train_count + dev_count + test_count)\n",
        "\n",
        "X_train.shape = (train_count, 48, 48, 1)\n",
        "X_dev.shape = (dev_count, 48, 48, 1)\n",
        "X_test.shape = (test_count, 48, 48, 1)\n",
        "\n",
        "X_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(30694, 48, 48, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q0trV9_iOvHg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import concatenate"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twQIOAbb0Utc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define the model.\n",
        "dropout_rate = 0.05\n",
        "\n",
        "def train_model(input_shape):\n",
        "  X_input = Input(input_shape)\n",
        "  X = X_input\n",
        "\n",
        "  X = Conv2D(filters = 32, kernel_size = (3, 3), padding = \"same\", activation = \"relu\")(X)\n",
        "  X = BatchNormalization(axis = 3)(X)\n",
        "  X = Conv2D(filters = 32, kernel_size = (3, 3), activation = \"relu\")(X)\n",
        "  X = BatchNormalization(axis = 3)(X)\n",
        "  X = MaxPooling2D((2, 2))(X)\n",
        "  X = Dropout(0.1)(X)\n",
        "  X = Conv2D(filters = 64, kernel_size = (3, 3), padding = \"same\", activation = \"relu\")(X)\n",
        "  X = BatchNormalization(axis = 3)(X)\n",
        "  X = Conv2D(filters = 64, kernel_size = (3, 3), activation = \"relu\")(X)\n",
        "  X = BatchNormalization(axis = 3)(X)\n",
        "  X = Conv2D(filters = 128, kernel_size = (3, 3), padding = \"same\", activation = \"relu\")(X)\n",
        "  X = BatchNormalization(axis = 3)(X)\n",
        "  X = Conv2D(filters = 64, kernel_size = (3, 3), activation = \"relu\")(X)\n",
        "  X = BatchNormalization(axis = 3)(X)\n",
        "  X = MaxPooling2D((2, 2))(X)\n",
        "  X = Dropout(0.1)(X)\n",
        "  X = Flatten()(X)\n",
        "  X = Dense(1024, activation = \"relu\")(X)\n",
        "  X = Dropout(0.1)(X)\n",
        "  X = Dense(7, activation = \"softmax\")(X)\n",
        "\n",
        "  model = Model(inputs = X_input, outputs = X)\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVHjxWyv65gY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Initialize the model\n",
        "\n",
        "Emotion_Model = train_model((48, 48, 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xvJJtbGlRybe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 884
        },
        "outputId": "9079f4df-89d8-4687-ac19-46f427b5a1d5"
      },
      "source": [
        "Emotion_Model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 48, 48, 1)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 48, 48, 32)        320       \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 48, 48, 32)        128       \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 46, 46, 32)        9248      \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 46, 46, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 23, 23, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 23, 23, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 23, 23, 64)        18496     \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 23, 23, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 21, 21, 64)        36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 21, 21, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 21, 21, 128)       73856     \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 21, 21, 128)       512       \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 19, 19, 64)        73792     \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 19, 19, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 9, 9, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 9, 9, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 5184)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1024)              5309440   \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 7)                 7175      \n",
            "=================================================================\n",
            "Total params: 5,530,791\n",
            "Trainable params: 5,530,023\n",
            "Non-trainable params: 768\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03GLRYOm8LsR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compile the model.\n",
        "\n",
        "Emotion_Model.compile(optimizer = \"sgd\", loss = \"categorical_crossentropy\", metrics = ['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TCC3dk9JKY1o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "4a926697-ee51-4d8a-dea7-bb2b4df5604c"
      },
      "source": [
        "# Fit the model.\n",
        "\n",
        "Emotion_Model.fit(X_train, Y_train, batch_size = 128, epochs = 5) # = 15"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "30694/30694 [==============================] - 18s 577us/step - loss: 1.6101 - accuracy: 0.3987\n",
            "Epoch 2/5\n",
            "30694/30694 [==============================] - 10s 337us/step - loss: 1.3206 - accuracy: 0.4955\n",
            "Epoch 3/5\n",
            "30694/30694 [==============================] - 10s 337us/step - loss: 1.2194 - accuracy: 0.5343\n",
            "Epoch 4/5\n",
            "30694/30694 [==============================] - 10s 337us/step - loss: 1.1412 - accuracy: 0.5671\n",
            "Epoch 5/5\n",
            "30694/30694 [==============================] - 10s 337us/step - loss: 1.0719 - accuracy: 0.5947\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7fa4600d7f60>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mTwc5kpICvKi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "outputId": "b29af171-c72f-4494-8aa6-79a85dd8485c"
      },
      "source": [
        "Emotion_Model.fit(X_train, Y_train, batch_size = 128, epochs = 10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "30694/30694 [==============================] - 10s 338us/step - loss: 1.0188 - accuracy: 0.6218\n",
            "Epoch 2/10\n",
            "30694/30694 [==============================] - 10s 342us/step - loss: 0.9638 - accuracy: 0.6420\n",
            "Epoch 3/10\n",
            "30694/30694 [==============================] - 10s 339us/step - loss: 0.9154 - accuracy: 0.6608\n",
            "Epoch 4/10\n",
            "30694/30694 [==============================] - 10s 337us/step - loss: 0.8705 - accuracy: 0.6808\n",
            "Epoch 5/10\n",
            "30694/30694 [==============================] - 10s 337us/step - loss: 0.8192 - accuracy: 0.7035\n",
            "Epoch 6/10\n",
            "30694/30694 [==============================] - 10s 337us/step - loss: 0.7750 - accuracy: 0.7195\n",
            "Epoch 7/10\n",
            "30694/30694 [==============================] - 10s 336us/step - loss: 0.7187 - accuracy: 0.7418\n",
            "Epoch 8/10\n",
            "30694/30694 [==============================] - 10s 336us/step - loss: 0.6773 - accuracy: 0.7551\n",
            "Epoch 9/10\n",
            "30694/30694 [==============================] - 10s 337us/step - loss: 0.6246 - accuracy: 0.7786\n",
            "Epoch 10/10\n",
            "30694/30694 [==============================] - 10s 337us/step - loss: 0.5850 - accuracy: 0.7930\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7fa46010d4e0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFPboTyHIaJ7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "outputId": "6558cbb4-1d5e-4916-ecae-648656180a44"
      },
      "source": [
        "Emotion_Model.fit(X_train, Y_train, batch_size = 128, epochs = 10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "30694/30694 [==============================] - 10s 338us/step - loss: 0.5400 - accuracy: 0.8134\n",
            "Epoch 2/10\n",
            "30694/30694 [==============================] - 10s 337us/step - loss: 0.4955 - accuracy: 0.8273\n",
            "Epoch 3/10\n",
            "30694/30694 [==============================] - 10s 337us/step - loss: 0.4536 - accuracy: 0.8450\n",
            "Epoch 4/10\n",
            "30694/30694 [==============================] - 10s 337us/step - loss: 0.4121 - accuracy: 0.8603\n",
            "Epoch 5/10\n",
            "30694/30694 [==============================] - 10s 336us/step - loss: 0.3800 - accuracy: 0.8716\n",
            "Epoch 6/10\n",
            "30694/30694 [==============================] - 10s 337us/step - loss: 0.3408 - accuracy: 0.8887\n",
            "Epoch 7/10\n",
            "30694/30694 [==============================] - 10s 338us/step - loss: 0.3098 - accuracy: 0.9000\n",
            "Epoch 8/10\n",
            "30694/30694 [==============================] - 10s 339us/step - loss: 0.2837 - accuracy: 0.9104\n",
            "Epoch 9/10\n",
            "30694/30694 [==============================] - 10s 338us/step - loss: 0.2608 - accuracy: 0.9170\n",
            "Epoch 10/10\n",
            "30694/30694 [==============================] - 10s 337us/step - loss: 0.2320 - accuracy: 0.9284\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7fa3ff54b400>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdZ0ryUwI6N6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "092c43dd-c267-4502-8ab7-0c8cfb86f599"
      },
      "source": [
        "Emotion_Model.fit(X_train, Y_train, batch_size = 128, epochs = 5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "30694/30694 [==============================] - 10s 338us/step - loss: 0.2101 - accuracy: 0.9365\n",
            "Epoch 2/5\n",
            "30694/30694 [==============================] - 10s 338us/step - loss: 0.1919 - accuracy: 0.9426\n",
            "Epoch 3/5\n",
            "30694/30694 [==============================] - 10s 338us/step - loss: 0.1761 - accuracy: 0.9467\n",
            "Epoch 4/5\n",
            "30694/30694 [==============================] - 10s 340us/step - loss: 0.1634 - accuracy: 0.9522\n",
            "Epoch 5/5\n",
            "30694/30694 [==============================] - 10s 340us/step - loss: 0.1489 - accuracy: 0.9574\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7fa46010c358>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THcGeMU0JPH7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "a0fb860f-ebf9-41ee-a94c-6321bbe118cc"
      },
      "source": [
        "Emotion_Model.fit(X_train, Y_train, batch_size = 128, epochs = 5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "30694/30694 [==============================] - 10s 338us/step - loss: 0.1340 - accuracy: 0.9618\n",
            "Epoch 2/5\n",
            "30694/30694 [==============================] - 10s 337us/step - loss: 0.1252 - accuracy: 0.9647\n",
            "Epoch 3/5\n",
            "30694/30694 [==============================] - 10s 338us/step - loss: 0.1165 - accuracy: 0.9685\n",
            "Epoch 4/5\n",
            "30694/30694 [==============================] - 10s 337us/step - loss: 0.1100 - accuracy: 0.9696\n",
            "Epoch 5/5\n",
            "30694/30694 [==============================] - 10s 338us/step - loss: 0.0989 - accuracy: 0.9732\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7fa46010c630>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlNAXifsNWUk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "2df87d11-3156-4e26-96d3-1026befa2a6a"
      },
      "source": [
        "Emotion_Model.fit(X_train, Y_train, batch_size = 128, epochs = 5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "30694/30694 [==============================] - 10s 342us/step - loss: 0.0977 - accuracy: 0.9741\n",
            "Epoch 2/5\n",
            "30694/30694 [==============================] - 10s 341us/step - loss: 0.0906 - accuracy: 0.9754\n",
            "Epoch 3/5\n",
            "30694/30694 [==============================] - 10s 340us/step - loss: 0.0876 - accuracy: 0.9760\n",
            "Epoch 4/5\n",
            "30694/30694 [==============================] - 10s 339us/step - loss: 0.0793 - accuracy: 0.9796\n",
            "Epoch 5/5\n",
            "30694/30694 [==============================] - 10s 338us/step - loss: 0.0709 - accuracy: 0.9828\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7fa46010c978>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eyl9fNARNmke",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "d200f721-a1ad-4722-8dde-e7b98c839cc5"
      },
      "source": [
        "Emotion_Model.fit(X_train, Y_train, batch_size = 128, epochs = 5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "30694/30694 [==============================] - 10s 337us/step - loss: 0.0722 - accuracy: 0.9813\n",
            "Epoch 2/5\n",
            "30694/30694 [==============================] - 10s 337us/step - loss: 0.0688 - accuracy: 0.9829\n",
            "Epoch 3/5\n",
            "30694/30694 [==============================] - 10s 338us/step - loss: 0.0645 - accuracy: 0.9838\n",
            "Epoch 4/5\n",
            "30694/30694 [==============================] - 10s 339us/step - loss: 0.0609 - accuracy: 0.9848\n",
            "Epoch 5/5\n",
            "30694/30694 [==============================] - 10s 340us/step - loss: 0.0592 - accuracy: 0.9847\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7fa46010ca90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ulmL5yDxK3-W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "e0e9b437-b252-46b4-e3a6-eae0a3eae020"
      },
      "source": [
        "# Evaluate model on the dev set.\n",
        "\n",
        "Emotion_Model.evaluate(X_dev, Y_dev, batch_size = 64, verbose = 1) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4089/4089 [==============================] - 1s 149us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.5797972715288715, 0.629493772983551]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxGzdT3a-SiK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "fc838c86-9754-4995-908d-fe0a042c71a4"
      },
      "source": [
        "# Evaluate model on the test set.\n",
        "\n",
        "Emotion_Model.evaluate(X_test, Y_test, batch_size = 64, verbose = 1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4122/4122 [==============================] - 1s 144us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.5091670078886532, 0.634158194065094]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2vrxp4bRFd-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cHJxAVUARKw5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "48276cd0-2cf0-4c00-8bf5-5bf74f0a0e7b"
      },
      "source": [
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bplMq_RmRjKA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_name = \"emotions-(1).h5\"\n",
        "path = F'/content/drive/My Drive/Model_folder/{model_name}' \n",
        "Emotion_Model.save(model_name, path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1S6CZqWNr6zQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import dlib\n",
        "from PIL import Image\n",
        "from skimage import io\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def detect_faces(image):\n",
        "\n",
        "    # Create a face detector\n",
        "    face_detector = dlib.get_frontal_face_detector()\n",
        "\n",
        "    # Run detector and get bounding boxes of the faces on image.\n",
        "    detected_faces = face_detector(image, 1)\n",
        "    face_frames = [(x.left(), x.top(),\n",
        "                    x.right(), x.bottom()) for x in detected_faces]\n",
        "\n",
        "    return face_frames"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sk9BU3rLz2Kr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "\n",
        "def facecrop(image):\n",
        "    facedata = r\"C:\\Users\\Prajeeth\\miniconda3\\envs\\tensorflow\\Lib\\site-packages\\cv2\\data\\haarcascade_frontalface_alt.xml\"\n",
        "    cascade = cv2.CascadeClassifier(facedata)\n",
        "\n",
        "    img = cv2.imread(image, 0)\n",
        "\n",
        "    minisize = (img.shape[1],img.shape[0])\n",
        "    miniframe = cv2.resize(img, minisize)\n",
        "\n",
        "    faces = cascade.detectMultiScale(miniframe)\n",
        "\n",
        "    for f in faces:\n",
        "        x, y, w, h = [ v for v in f ]\n",
        "        cv2.rectangle(img, (x,y), (x+w,y+h), (255,255,255))\n",
        "\n",
        "        sub_face = img[y:y+h, x:x+w]\n",
        "        fname, ext = os.path.splitext(image)\n",
        "        new_path = fname + \"_cropped_\" + ext\n",
        "        cv2.imwrite(new_path, sub_face)\n",
        "\n",
        "    return new_path"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0gYLYdBZsolp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "45785410-9664-42f1-d654-4bb44387f042"
      },
      "source": [
        "image_url = \"https://drive.google.com/file/d/1WMadxACCP5O_kHL2hd9pxqaXHG91Im4g/view?usp=sharing\"\n",
        "image_id = image_url[32:65]\n",
        "image_id"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1WMadxACCP5O_kHL2hd9pxqaXHG91Im4g'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z58f75Kys0cM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "downloaded = drive.CreateFile({'id' : image_id})\n",
        "downloaded.GetContentFile('image_4.jpeg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qMREtBhftOXd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 850
        },
        "outputId": "068dad0f-43a2-4b02-9a01-b2b75c2a9104"
      },
      "source": [
        "# Load image\n",
        "img_path = 'image_4.jpeg'\n",
        "image = io.imread(img_path)\n",
        "image"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[236, 237, 232],\n",
              "        [236, 237, 232],\n",
              "        [236, 237, 232],\n",
              "        ...,\n",
              "        [164, 136, 115],\n",
              "        [215, 184, 164],\n",
              "        [210, 179, 158]],\n",
              "\n",
              "       [[236, 237, 232],\n",
              "        [236, 237, 232],\n",
              "        [236, 237, 232],\n",
              "        ...,\n",
              "        [213, 185, 164],\n",
              "        [229, 198, 178],\n",
              "        [216, 185, 164]],\n",
              "\n",
              "       [[236, 237, 232],\n",
              "        [236, 237, 232],\n",
              "        [236, 237, 232],\n",
              "        ...,\n",
              "        [228, 200, 179],\n",
              "        [232, 201, 181],\n",
              "        [233, 202, 182]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[ 52,  55,  62],\n",
              "        [ 62,  65,  72],\n",
              "        [ 59,  62,  69],\n",
              "        ...,\n",
              "        [ 14,  17,  22],\n",
              "        [ 33,  36,  41],\n",
              "        [ 12,  15,  20]],\n",
              "\n",
              "       [[ 57,  60,  67],\n",
              "        [ 57,  60,  67],\n",
              "        [ 37,  40,  47],\n",
              "        ...,\n",
              "        [ 12,  15,  20],\n",
              "        [ 31,  34,  39],\n",
              "        [ 20,  23,  28]],\n",
              "\n",
              "       [[ 79,  82,  89],\n",
              "        [ 45,  48,  55],\n",
              "        [ 13,  16,  23],\n",
              "        ...,\n",
              "        [  8,  13,  19],\n",
              "        [ 29,  32,  39],\n",
              "        [ 28,  31,  38]]], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yd-Fgt_dRjpM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "outputId": "659f3137-fb10-41e7-d14c-1c5516e014dc"
      },
      "source": [
        "# Detect faces\n",
        "detected_faces = detect_faces(image)\n",
        "\n",
        "# Crop faces and plot\n",
        "for n, face_rect in enumerate(detected_faces):\n",
        "    face = Image.fromarray(image).crop(face_rect)\n",
        "    face.thumbnail((48, 48), Image.ANTIALIAS)\n",
        "    face = face.convert('L')\n",
        "    face.save(img_path)\n",
        "    plt.imshow(face)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD6CAYAAABnLjEDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO2daYxk13Xf/+e92rq6eu+enuasnKEkLpJFyhNGjmxFoS2ZlhhJSBTHlBMwAQEhgANIsAOLSoAkBmxA+mLZQQIbRKSYhgVRsq2AAiNHoWgqihOZ0pAabkORM1xn7WV6r/VV1c2HrpHmLN1VM9PT3cN3fsBg+t2+7777lluvzr/PQiEEOI7z1ifa7gk4jrM1+GJ3nJTgi91xUoIvdsdJCb7YHScl+GJ3nJRwVYudiO4mopeI6CQRPbBZk3IcZ/OhK/07OxHFAF4G8EEApwH8EMC9IYTj6+0zMhqFG/Zmruh4l0sMfV51xGz7VHVE9clEbbadj5uqT554G5E+PhnHj9HWHQVyrwA9uHG4ruNcKdZ56GN1n1FMvZx793GSdqza2mK/ZjD6BN5H7mP1AYBWu/v7kIhfo2CMo45nXFY5jvVcSeTyrU8vIVmqmntezcq7E8DJEMKraxOjhwF8DMC6i/2GvRk8/Oiuyz5QdAWPbn+kH67XmyW2/Znn/6nqs6u0yrYPlOZVn0N9c2w7Sy3VJx8lqm0gqtqTvYS2+LJVa2dVH+t4kpYYx3qQe6FgnIekEfRjJI83mlk1+vA5yjlbnG6MqrZKO8e2LzRKqk+9zedYbuZUn4rRtljv6zqnQoZfo1pT37N6i38AWR8ihQx/icTGMyyR4xz7jT9dt+/VfI3fA+DUJdunO22O4+xArrlAR0SfIqKjRHR0Yb77J5XjONeGq1nsZwDsu2R7b6eNEUJ4MIRwJIRwZGTUxX/H2S6uxmb/IYC3EdGNWFvkvwbgk912uhL7OxbChSW+NYT9VzDUjcVWkW3XE336w3luV/fF2maVNnMprqk+lhgnzyMxhKRux1pr47adtPMBKAEogbYj5Rwt+7wV9Nhy3patLce2tIda0DayRNr+1nzkMzWY0dqInLOlYaw286ptpc7nOFrUY8s5ZWN9z2pN/qwN5OuqTyXh16hlzLGYlfoAH3cjkfOKF3sIoUlE/xrAtwHEAL4cQnjhSsdzHOfaclV/BwshfAvAtzZpLo7jXEPciHaclLA1Hi6XgbRrAdtG72U/SaXNbbI41nb1aK7CtkcyFdWnJewiy/7LGX8jtWywblh2tNYDtI1YDvxc5d+0ASARTkZFaDvSsseljmDpMPKayGsPAInx9/luWDqHbLP6yPlkIn3NcpF2oDowtMC2ay2tPVSS7tqDtNGriaGhiGc4n9HzkecRSUecDdaKv9kdJyX4YneclOCL3XFSgi92x0kJWyrQEXoT0jYD61OsIYQbGeEGAH1Rg23LIAsAGM+usO3hWIt48lgAkBPCVrnd/fIXSAt0kYggs8S3bvsAQLaHKDxLoFtq8eCQxDiPAeFoZAUGSS3JmmMv4psMcpHba8cXjkjGNbOEVhkcUzCiIDN5fq7nVgZVn+E+7owjhTVAO+NkjOuxKsRAOeeNnGr8ze44KcEXu+OkBF/sjpMStthmDz05yGwGsZWJRHy2WQkEpE1YirSjibSje0kmcTn9Lnsfw7aTmWEKMJxzesgeU6CGaqsTdwiJI31PpY3eb1xHSS8OMxa9JOaQNvJ0bUD3MZ7N0TzXY+brRdVHjl0yglyaPWS8KTe4PZ609D4yC05GOoZtsLz8ze44KcEXu+OkBF/sjpMSfLE7TkrYcVFv1xKZUSRpavFHpiG2RBvpaGIJXZawJKPlrP0i4ehi9ZHnYYmevQh78ljS6QewnYOG4nLX/Zbb3PGml4g/M7uPODczClBcIyubzXKzwLYzxpyXGt0zyQ7mdFYi6XhjOczINivddC/ZZJUTzWVEUvqb3XFSgi92x0kJvtgdJyXsOJv9yj99RJYP0plA/nb5MNuun9aVQ/5q8Z1su29Y22i3Tp5n20NZ3efm0jnVNplZYttWkIvEysoqsezYLER1kSsMerEywEoHGUsfsJxxJIORDA4xNIxW6NqnF+Q1srIGzzf6VduZyhDbbhjlp3Ii601fRo8ts+DUIn1fq6KSTDBseJlNdn5FaCMbOO/4m91xUoIvdsdJCb7YHScl+GJ3nJSw4wS6XrAkmqzwLagELZJ855lb2Xb/eaOUkMgEQkYZ36cPcWEv9OvsJUfH96m22ya4sPfuwdOqz0imrNokOVH+ybogUsiynGN6yRqkjmVQNrL5SPojLdjJMla1oEWrYeHAYwmNPUXGRcKhytinP6Oj1YoZPm8rwk5mr7HKSKn5GONIx5tKUy/PlWr3sdfD3+yOkxJ8sTtOSvDF7jgp4bq02S1kieZnGjrD5+hRfrpN7UMB6cMy9Kp2GOk/z4+1sk/brOUpfWl/UObBGH2Hta5wuDirJyWYzHLnnAYMe1wF61hltXpxtNG2pQxqWWrpCynt8fmWdmCSzjiWHS0dj6wgE2nrW04+MkuwZVfbZbz4WDLoBQDa4hoNGk5WiyLIxgpg6VbaCQDy2eaG29EGwTT+ZneclOCL3XFSgi92x0kJvtgdJyVsuUDX7dMl7iHxhuVCIccdFhFVALB4s8gWkjXEDKGJBDKcL87xToNvGqWVyvpElmIuCr0yMa76yLrhE7lV1UdlyjGualucR9FI5SxLIJWNGupLLZ06WZZ/Ol0dUX1eWebndn5Rp26ur/DjUawFqbFxXmrr8Mic6jMgnGH6YsuBh1/XquEIVG/p5SCj45pGFpzFOr8epay+1nLsuuEw00s2H0lDjLNR5hp/sztOSvDF7jgpoetiJ6IvE9EMET1/SdsoET1GRCc6/+vvcY7j7Ch6sdn/BMB/BvCnl7Q9AODxEMLnieiBzvZnN2NCLSM2Q9rxVp+KMLYPGNlC8vu5/Vuv6sCL/gHuEFE4rANBmm0+odl57TAST2v7Nz/HP1vffHG36lN/O9cI/t6u13Qf6fnTy/czQ56QdmzFsNmnE+2ctJhwG/XY7A2qz/zpYT7Fqp5kUVwPq3TRwgV+rk8Wh3WngsgUM6Bt5tESL+M0mNeOLwUje43l2CKRwTK1ln6upI2eGBllGiLbcdLSelGjwcdp1Pix2leTqSaE8D0A86L5YwAe6vz8EICPdxvHcZzt5Upt9skQwsUka+cBTG7SfBzHuUZctUAXQgjYoHYkEX2KiI4S0dH5+StLFug4ztVzpYt9moimAKDz/8x6HUMID4YQjoQQjoyOuvjvONvFlTrVfBPAfQA+3/n/kV52IvTmNNMNa4xEfLcYiguqz10HTrDtbx2/TfVpiZrY82Utvo0Oc6Fv/5SUNIALg9oZpbzM5xQq+vKfP88FqPkRHVG2O8+j3mqGM8hAxAUoKwtMDbxNRoYBQNUQm5aEQFepaWGPWiKCq6FvmswKXZjTXxCLIsIwRFq0qo/y829n9Hxmi9yp5/whLdCNj6yotuGCTHet55gRkWYZI921TC+dNPQcq3V+/ZvN7i/H0BB9Nvjy3Muf3r4K4PsA3kFEp4nofqwt8g8S0QkAv9TZdhxnB9P1zR5CuHedX/3iJs/FcZxriBvRjpMS3jKZauSn1kJb22T/bOz/se1vT79H9Rn+H9xusuIKIpGtZGGvtiNXb9HOOFE/t9toQDtxtOt8rGdnp1Qfmc3GKlFslXGWyMwwS01dsniurjWLUytcV2gZtiUNcUeTZtEoYd3P29pZ3Ucm280t6fPqPycy6ZaMmyYyGbXOaZt5ZkFrFtN5Pnb/WEX1GSpyuz4X60w51YRrH1Z55myG79dMumfNjYRDEaL177u/2R0nJfhid5yU4IvdcVKCL3bHSQlvGYFOOtpYn2KyJFLxnFGCp8n7XLhNiyS7nxQlgfK6T+mkvrSNEd6vMaaFnLjMZ74yO6b6PD3ES0u9e+iM6mOlgJbMNLijyWKiHYGmqzrDzNkzo7whMa52TghQLT2fUOIiZrVklJoSgiUZzjlSRQ1FYxyZBadmiIrGHKNVfvz6BR0FeHYXFzZz/TpTTj7PxdjhPi0gy1TSVgRb27rWl+KZahzH8cXuOCnBF7vjpARf7I6TEnacQLdZnz5J0J5Et2ZFOuE7dS306i4uUk3ccV71Kb/Bc3XsekqnQVrer72x7v7k37LtF5d1Wqofn+VjRye0aHbsNS7QHbnjTdVnVNQ1nzfqsUkPuoWG9qB77fSEasuIVFGtfu0NFs+KPpNatAp1kRJ71fCyG+D3rHCD9mAr9fHrb3mnFTLd68yfnR9SbYlIXUZ5Y5yaSBW1qL3zGjk+Tr2uownbrR6i3ORjLQW7DRwn/c3uOCnBF7vjpARf7I6TEnaczX6lSCvNihdqCYPm9n2nVZ8frhzqeqzGP15g26ef02nzb3v/Sd1W5M4vZ6o6LXKxyO3P/jt19pRe0hsXIu7EUQzaZpa8PLdLN64aZYom+RyLx3VWIFkivQajrnlOnEdbO4QUX+O2bXRS27pz+/nBSnuXVZ/5Za5ZBONYmax2ckIfv46NJW2Po8nHImNs1PgT2VzU5xGyojxZ0ZhPD/d+PfzN7jgpwRe746QEX+yOkxJ8sTtOSthx9dmvFCl3ZMmoj97mgsdqosWW3BAXn86e0+JbrijEr3ctqD7zNe3E8s2Zd7NtqybY7ZNcxLutdE71kemj6qH7bVT14QDM1HlEW7WsRbSxg/rcLszx/YKhhlaEaGZFomXP8+MpwQ5AbYK33fR17VRz/r08dVb//9HOMZlR/jxUdLYvNIr6+K2SkH7zhmgmarRZ6ZzjmojMM2rRtwuizRLjpPh3GXqdv9kdJyX4YneclOCL3XFSwlvGqUZSIG1IPt/gQSUyMwgAHBznpZzGCjpYRjq1LCfaqaScaPu30eaXu5TVATTSRpfZdQDgzSrPFPP+kZdVn4GIpzc+2dKFdqcr3PYeG11VfW4b04FA31vkekTmTm3Xf3QfL7X1yLPvVn2ScW7H/+77v6H6/N5zv8K221mtPRTm+f0Yekk71fSNcZ2DjFJXUWJlweHP0cpBvWTqe7jDUoj0O7Ql7iMZxyJRyilkDeNf2ey92/D+ZneclOCL3XFSgi92x0kJvtgdJyW8ZQQ6WTUtawh0P65zTworeuymwRm23TbqqB3om2PbBdIOI+ca2rFjWTjDyDrrAJAV4WLPre5RfYazXHwbjrWIWGkb0VmCgRwXCPeVtNA2JI4FAMV+vt8v7HlV9RnPcrHv0L5Z1We+zAXTv164RfX5lzd/n21/9bYP6WM9yx1tFm7T6Z4XPsr7JHV973f9Ly3ayei90inVBXGN75cM6LGbwjknGA5EISPazFdx90jB9fA3u+OkBF/sjpMSfLE7TkrYcTZ794rUNtL9oGVkl32lxjOx5CId1DCW5favtKEtZJZWAMhH2o4fznK70aqr/nqNl3taMYJ13lbkukLOmmMP8x7O8fmUMjqbTSnWjj99Oa6QLDf1HPtirk9MFbWjS0XULH/y7AHV50Q/z267/16tD5z6CNdHchntHDQinE/mmrqs1dztqgl90/welQ/o65qb531yS9qOTob581iY0FqIrHMfDKevZlk4FcmAmg1MeH+zO05K8MXuOCnBF7vjpISui52I9hHRE0R0nIheIKJPd9pHiegxIjrR+V9neXAcZ8fQi0DXBPBbIYSniWgAwFNE9BiAfwHg8RDC54noAQAPAPjstZvqT7Gkp4LITNM20oXMN3i01lheO6NcSHgfS6Aqie04ki49QNHYz8oW022OGaOUkRzbEvoWW9xhZbahBSkZhVdvGWWcZJ11AG8f4Q4yLy/oFNSNoe6P1lCe1yi3BKnZZX61T70+rvpQgT8RmZx+QhJZkskQsmiXFihHRBYi6422VOVRjytLuoyWTCVdyOlnpibyLSUNfQ0z/Xy/ZrV3jb3rmz2EcC6E8HTn5xUALwLYA+BjAB7qdHsIwMd7PqrjOFvOZdnsRHQQwB0AngQwGUK4GHx9HoAOmF7b51NEdJSIjs7PG/G5juNsCT0vdiIqAfhLAJ8JIbA/moYQAtYJmw8hPBhCOBJCODI66nqg42wXPX3hJ6Is1hb6V0IIF9OJTBPRVAjhHBFNAZhZf4TesezxK3G0WWlrp5aqyOa6q6BLK0lnGMtmH8pwZxQrWMZKuSoddKwsNDJ7zkBGH1+OExvjvFzj5aAtx5ddeX7+VmBQ0tbnMVXgATzRiD6+zNx7Y/8F1ScnrrXleNM3wW3U6j6te7y8yB1vJov6vi6Mcw2jmuhxxotaw0la/PznKrqE9p4hfj0GJ6ZVn1MrvNRXLdFLT5aeXmoaGW9kWefNLNlMRATgSwBeDCH8/iW/+iaA+zo/3wfgkW5jOY6zffTyZn8fgH8O4DkiOtZp+7cAPg/g60R0P4A3APzqtZmi4zibQdfFHkL4G6zvcfuLmzsdx3GuFa6YOU5KuC6j3nJGaaes/PJhfBdpCiGtbIhWh0vcYaRlDBQLhx1LIKsZJZlKMXcimUl0RhU5x9GcFo12Z7ggNNPU48jSThZSkCtG2qkka0QGLje408jN/VqQks5JVhTg3sIi215t6fshBdLRrFag9k/x9N+rxn2Vabut0luNlrEcxAP5nl1nVBd5jerGOGN9XNQ9Z9yzlsg6E8X6uUqqYt5e/slxHIkvdsdJCb7YHScl7DibvResLDQNYbyMRjpTaEbY1rM1GdICVIp6P0kiMtdaTjU1I+hFZqG90NDHl3bjaEbb7JIzDR2esdTgwRmFWNvMUnsoxtpmt+gXjj4DQosAgBtyPIDk5epu1ednijxV63JbB5BIXcPSFc7UucOKFTz09n7u8yXLXgN2VqKhDM8oY2UlOlXrHvAZieezXDOezww/viFNqTLOpLLLrp+qxt/sjpMSfLE7Tkrwxe44KcEXu+OkhG0X6KTcERuqhCXIdRvHKv80nucphp9e2af6rLS4sGWJT7EQW6wo/YKRvUYy39ARVNL5YzKrS0SVRW1xWa8dsJ1GJIsJP76VSSdjONVI0WqppcWuiQyPYJNiHKAFscFIp1eGzJxsXO2owNssoU0Ka3nj/swl2hFpRmT4sQS6WIhmsSGGyghHKcYBwKrIcBNkRBsAtMT6aHp9dsdxBL7YHScl+GJ3nJTgi91xUsK2C3SbhZRbrFTSf3eA1wl7ak4LdJYAcyVYKadkBN1yUlB9bhk8z7YHIi0Qnk24x5YVZSXTW1lefoloi9p6nLrRJoXF/X26rrv0hrPEt4LwhmsZNeVzwuswMu7rcMwjyhpGxKEU9qzrMRTrOSaR8JY0PNRkmu7VpvaOm6tyb8laTYuhcZbPsVk3xMAV3hbX+Hw2KvHnb3bHSQm+2B0nJfhid5yU8Jax2WX5pyRo4+VdeZ5lpJDRzg+y/NJ4VqclLkbc8SUxbETLZq8IZxjpQANohxULOU7ecOKQWLZmRdiWbWOcybxO7yx1DStTj3RQqcTajm2Jd03LKP8kowetdNfSGShL+jwqQg+wtJlRo677dMJrv1tZcCQyjTYAJG1+ru2WPn6Ql9EqUSWcaIxLvy7+ZneclOCL3XFSgi92x0kJvtgdJyW8ZQQ6SaLUDmBUpCsaMASyuqhtJiPcAC0SrTS1c4wl7K2KiDpZaw0AprKLqk2iasYZc5Q122fKOjJN1keP8locrLa1sDaQ4ftZ9eETEYe41NQRflJYGxLOMQAw3+TOKFKcBIAzNZ6WajynhTaZktoSLGXEIwC8Xhnj+xkionweZN17AKjUhRgqo9Wgo9yoaryLRZNOS7U+/mZ3nJTgi91xUoIvdsdJCVtus0tLOhHmpmUjS4eZhpW5RrYZpszeDLf/3jGoyxadWOG1vi3nC9lmOWNYWV9eE/afTG8MaIeQlba2I6VtKQNaAGAkz+3fxaq22V+b5RluCgWdvWW4Twfi3DLCg3UO9c2pPtKpyLoe0v62HJGyomxUwbixss67zMADAGVRWqrPSkktbH8AWKzz6zaaN3SFOj/ecl3fs1qdn3+QddYBwKjHrhCXSPkPeaYax3F8sTtOSvDF7jgpwRe746SELRXochRjf0bXN+tGPXDhyEotLVNHR4aQ895jn2Db02d0ja5/9J6nxLGsDC/8WFba6LmmTkssUw5bmVFkn7YhuMjU0Vba6KaIsqol+lbnchukNekwvajPY7jA532gMK/6WOmcJfLaWiKedBiqtLRTzQ15nm7bElWlaGeJeFLoA3SNPCnGAcCFCo+UrDaM+9EQc5IpoQElrlkOM3KKxuO5Lv5md5yU4IvdcVJC18VORAUi+gERPUNELxDR73TabySiJ4noJBF9jYi61zp2HGfb6MVmrwO4K4SwSkRZAH9DRH8F4DcBfDGE8DAR/TGA+wH80UYDvVwbwi+/eA8fXGRGHcxrJ45fnniBbd9eeEP1OVY7wLb/+L/9Q9Vn/5/x7LK1f7JL9Yl+VpZ26h5oIDOuALbdKAM0BgybfUBkYS2Q1gMOF2fZ9omKPo+qsOPH+rUziLTr5TYAVCo668qJGe54dKiknWr25HnGWavcUi92vXS0yRpZgeQ4xVgHOKlsu8Z9XahqfWKuyu3xBSOgKEn4vW7W9RyDtNmNQBhKei/ldBFpwxuJfH7at9tgYY2LT2m28y8AuAvAX3TaHwLw8e5Tcxxnu+jJZieimIiOAZgB8BiAVwAshhAufq6cBrDn2kzRcZzNoKfFHkJohRBuB7AXwJ0Abu71AET0KSI6SkRHk6XuyRQdx7k2XJYaH0JYBPAEgJ8DMExEF42TvQDOrLPPgyGEIyGEI9khbe84jrM1dBXoiGgCQBJCWCSiPgAfBPAFrC36TwB4GMB9AB7pNla9ksOrT/GSS5NPipI3z+hIsEcL72Pb/+nee1Sf/ndxx47hk0b96yP72XZjSHXBqSp3tMkW9Tglo2a7ZCRTVm0yLbLlsDPbHOTHN9Iir4oIrtNlHa1VSbrXZ09EOmMrtfbIoBHltcBFq7m6dpQ6WOCinczSA+jrYSEdlpK2Fj6zMb9H1rGkYJoxxEErTbUULYORqaYt+9SMEmLSQSZjKGmGaKcQXWRSHGN6Pz1k99ExBeAhIoqx9k3g6yGER4noOICHieh3AfwIwJd6GMtxnG2i62IPITwL4A6j/VWs2e+O41wHuAed46SELQ2EoQBI34rpvyMcOwqTar+x/32KbZfe1AEshWd4W2VCGy+T93JnnEkju+ysKK27zyhHbAVs9NLnVIXPsWyUEhoTjjcXGtoe/sEM1x6WnxpXfQa5/xCK09oep35+7U/9krYjR/fobLftsizJZGSYETax5WQktYeikT2mlxLaUvtYamohWF7rFePaWzZ7LDISZzLa1m+JrDOtnL4eFPOxo4xR0luWujJKNkd1/lxvqlON4zhvDXyxO05K8MXuOCnBF7vjpIStzVSz0MKN3+D1vkOWixDVScMhYj8XoCaf0I43OM8jwYb2aKHvdOkgn8+KVjOW7+JOJLcNn1N9pDPIXNJb9p1dBV7u6XtnDqs+K6tcXGoZ6YULL/FrNPy6FnvKU3y/uTu02CPFnKimRc35M9phJx7kQtptJX2N2kI0sxyIZC16KwtNSzisWJFyy6L8loz4A4CyqEW/3NDPmSXQyQw/jYYR0SYcZrJ9OsIvlgJdpO9ZZUmcv1WfXZy+kVxnXfzN7jgpwRe746QEX+yOkxK21GavT0R46V+J7JzCuSDOa8eK+FW+z9T/1bZdcZYHwlBFB6vs++88MC+Z0vbohTtFaV3D1pTZXWeNQJDBrD6+dD6R9igAtM9zWzJuaMOtOcDtv+m/r+3YwggPxOkzbMR8lht8xZy2NfcOaKeaW0q8/JOVhUY6w1jOMdK2tjL+yGwtTaOPlSm2G1bpZfN+iLa2UbYpisUzHOtr3Wzy868bGYAK5/lyDLHhISOmLauFbxQI4292x0kJvtgdJyX4YneclOCL3XFSwpYKdJkyYfz7/JD9IhorP6sFOkRcbKqPaHFDErL61N741Sm2Xd1jpDJuc3Fl2YiOemWJO/nMLWmBzoqOIpllxCjvE09VRR/9edxc5sLWwC5dH/7QCBcspyt6jpU6FyPzRqaavliLbxJLfJNRf1aaainIlYwU0LNG1J8+vkyJ3T1SznKgaRnqlpy3dT8yWX6vrWw2SVU4+iwZkZNyN0ttE9POiltvBCD+BH+zO05K8MXuOCnBF7vjpIQttdnjahujx7n9nZS47RJi/fmTPSscZn6kA2Fad7yDbc8c0bZeW/ji3PRn2vGlvJd7Kazeom32C8s8u2o+b5Q2irXN3hTZXCPjo3awyOc0O69LEkUlfjzLjiyJLDyFQT3Hly9MqDbJm6s6K5DM8GrZ9YMiyMVyfJElmBoyVSqAvIj0aBr6QFYYqhV5o6Ht+IWazmbTaBqZYYRtn81pXUPqM6tLemxaFM+5YY4n/fxYuWUrEoZveslmx3EUvtgdJyX4YneclOCL3XFSwpYKdK18hKXDQqgRgkN+0cqowkWieFk7kdApXm5oal6XXwqneUYVyhinv/cWtllparFnoMjFL0vY6TciyIpZ4RzU0sdvyJJMfdrJSKYubhrZbM6UjdpWgjjiglC5oc91paoFShkdJtMtW8hSUwBQa/Lzt0TNm4e5GGuJgVLosyLa5mv8ubMcX1YrRvYacY16iWhTtdgBZEQWoHZWO/Vkeqh7mtWPdc/4m91xUoIvdsdJCb7YHScl+GJ3nJSwpQJdiIBmkQsVE9/ntdSiFa1AtOe4Bx1K/apPqIuIqWHteVb+0DvZditnpDd+nh/rtQujqs/uYZ4O+81F3ccSifqEF9tIXtc+L8TcQ2sgpyPBLlT4+U/0a8FSerktVrVX12CBe+vNl7WXW8EQGldEtFzdqAXfECLV8IBWn8o1Po6MCgSA+iB/RPOx9mCTaaItL7ulqhbfJEMlPcdqg59brapFTCW1GdmkWnmRSjox0mKpoY168QW+X26J/96j3hzH8cXuOGnBF7vjpIQttdnbg22UP8Tty0yVp3MefsGIPCpz2zYsLas+dGAv2y4f6u5UMvTcBT3HorBHKx6j1F0AAAszSURBVNoezY1y549iv7arrUwoJ07vYtuFk9qOrN7InWg+cOtLqs++fp7eORtpZ5Q+Uev8jVxvuoLEOo+Vuqh1Xtb3bHSQ37PESsEsHFYse/i5GZ5daGpQ33vpIEPGnFX0mpFJaKigoyCXy/weNY2a6VJroLweOyT8/INhW0dG5iLVR9Zjb29QkF3u23NPx3Gua3yxO05K6HmxE1FMRD8iokc72zcS0ZNEdJKIvkZE+juY4zg7hst5s38awIuXbH8BwBdDCDcBWABw/2ZOzHGczaUngY6I9gL4CIDfA/CbREQA7gLwyU6XhwD8RwB/tNE4oUWozXPBY2JF1D8r6S8I8SB3kGndtEf3eYVHtBUfP6snEAtxZf8NqsupD3FhL/+aHmZhnDuoFLLa0WOytKLacqM8Mu+FwpTqg2Uufn33+XeoLvlBLgjWV3VkWrQobq3xsd7uE0LjuHbyGe7XjiZSACsUjHrkIhJOOqcAOlosZ6T3qoiaaCsFo0aaSIG9aESv1cTxrSg86eRjEWW0shZEXXVqGinCK7zN8PtRjjeZFSNttbhFMgpuM5xq/gDAbwO4ONQYgMUQwsWrfBqAXoGO4+wYui52IroHwEwI4akrOQARfYqIjhLR0ZbhCus4ztbQy9f49wH4KBF9GEABwCCAPwQwTESZztt9L4Az1s4hhAcBPAgA+YN7e/+joOM4m0rXxR5C+ByAzwEAEX0AwL8JIfw6Ef05gE8AeBjAfQAe6XqwXAu79/NAk1aOl1IKGSvHLrfJVvfpoI549418nEiPM/cubijVdmtb+6avCKMo1uOceSe3G6eGtaOHTOUM6Cw099z0vOqzJ88dZl5Y1brCcxe4rT8nSwsBCCITSlTTX+IGTvH9ohe0I9L8sG5rjHDDsN2nDcXV5iCfT592NBke5w5WkZHxplbh9nDcg5OPlVpbjVszrllL3+u2COghy2aX52Y4GbWEjJAp62PJ4BhZ2mmtjZ9/W57GNarP/lmsiXUnsWbDf+kqxnIc5xpzWe6yIYTvAvhu5+dXAdy5+VNyHOda4B50jpMSfLE7TkrY0qi3gUwdPz/5Kmv7zuQk2+4/oyOPwiDPzFKY18Ja/mk+bvLOg6rP6HEu9hQfN2rBixCmYKRPabzGnXzat2sHmlrTcCIRhbmenNVzLIssMDeO6Mi8X9j9Ctvu26OdUQoRb1uRChGANyo8Em6xroXPRaMmmoxgkzXs1tp4n7rhsCIdW1qG400UC6HREOjqSffHuJmIOnvGOJajiwwqC1XjWFH3PzJlqrThNgCIW4b8Yvdx68MiRfUGpen9ze44KcEXu+OkBF/sjpMSttRmz0VNHCzwYJDyDdwumfqf2kFl5h/sZtt9c9qxIbPAs9TmXtcZaLPHucNM+6AORDn/Pu5EcsO3dS34fpFxJvMeoyRQD4WzFyvaHi5f4Blej53WTi3PDvOsPK0VbetCZEvJ92t9IiMcRKzySy0jm81YP7+O0lkIABqitNOIEVCzUObnnyRG2SSRUWZuVd9X6SBj2ePNZRGs0qd1nyij9yPRFqzMMKIpawSwZEWt9Vj7XKEwL0pNNfSxqqN87NwK70P6Fv4Ef7M7Tkrwxe44KcEXu+OkBF/sjpMStlSgi9HGQMSFGplZo3p4TO3XuoeLb6X/oD+jglVrXSLFFcNhpnSGKxztks6M0hRVks4tDao+N43NqTYp2o3268wwMvJrdUmLeK0GH4eMUkIhFk4ti9qpJhEiFZW0apQxItGkM4yVhaYoykblM1oQ6y9w0VBmrgGAhhDfEsOBRUartWpGuueGcJYySn+1akbImGwystDk5vnxsqu6j3zOi9NG9JyYUnnSyFRT4+c/8Ca/zpaodxF/sztOSvDF7jgpwRe746SELbXZF5pFfGP6Z1nb5FFuI8+8RwdM1E/wElG7f3xM9YkGRInmoG2XlnC8WX67ztxaE04LzYIu/SwdIlYWtV1dHdJ2bF+mux07UOCDWxlVmnPieAN6nMFhrgdYjiayBNJ40SiXbTjVVBJ+j0p57bCTiGwx1jgyA61VMnmuxq9/WNDPh9QsQlHbwySz0FS0XR+yxn6ibFN23nCYEVln8vP6WpfOCS0oq6+HtNEt+7s4w+fYd5oHYUWN9b1q/M3uOCnBF7vjpARf7I6TEnyxO05K2FKBrraax/HvH2Jth1/lollc04KYFNuoTwtiNFjiu6xqsSkqcm+Y5QP6sy4ngu6kYAcA/ee4SFKb0CLawNt0xp1Kk4tLYwU9xzHt+6KYFduyzjkA1Bv81saxFp+kQFdv6ceh1tRtMp2zFRknscotZQ2HHUkQGW8MnRHtISFQNvQ9k04tUdnoY0QqijL3KJ5TXVBY4IPnF7RgKlOkN/OW0Me3LYEuv8BFXloWO7XXv6b+ZneclOCL3XFSgi92x0kJWxsIUwNGjvO2IMoo56d1cAglwlFgfET1aY7wDCZ0dlr1iW7cx7ZlZhBAZ/6oD3W3R4tnu/cBgFzUEtvathvN8fPfU1hUfc4N8Ow1mUg7Ury5wjPHFjI6A63EstmLWb1fJFKzWPtJhxnL9pcZbuaXi6qPNNKtcsi0wsduF7Td2i6IcsjLRkDLktEmMrz2XdBjy8tfG9Xn2srxsaOmfvaihLdly0ZGpiXh0dUUz5DhTPaT8df9jeM4byl8sTtOSvDF7jgpwRe746QEChsY9Jt+MKJZAG8AGAegU7nsbK7HOQPX57x9zlfOgRDChPWLLV3sPzko0dEQwpEtP/BVcD3OGbg+5+1zvjb413jHSQm+2B0nJWzXYn9wm457NVyPcwauz3n7nK8B22KzO46z9fjXeMdJCVu+2InobiJ6iYhOEtEDW338XiCiLxPRDBE9f0nbKBE9RkQnOv9rB/1thIj2EdETRHSciF4gok932nfsvImoQEQ/IKJnOnP+nU77jUT0ZOcZ+RoR6SyT2wwRxUT0IyJ6tLO94+e8pYudiGIA/wXArwC4FcC9RHTrVs6hR/4EwN2i7QEAj4cQ3gbg8c72TqIJ4LdCCLcCeC+A3+hc25087zqAu0II7wZwO4C7iei9AL4A4IshhJsALAC4fxvnuB6fBvDiJds7fs5b/Wa/E8DJEMKrIYQGgIcBfGyL59CVEML3AMyL5o8BeKjz80MAPr6lk+pCCOFcCOHpzs8rWHsQ92AHzzussdrZzHb+BQB3AfiLTvuOmjMAENFeAB8B8F8724QdPmdg6xf7HgCnLtk+3Wm7HpgMIVxMSnQewOR2TmYjiOgggDsAPIkdPu/O1+FjAGYAPAbgFQCLIYSLsZs78Rn5AwC/DeBiDOoYdv6cXaC7EsLanzB25J8xiKgE4C8BfCaEwDLq7cR5hxBaIYTbAezF2je/m7d5ShtCRPcAmAkhPLXdc7lctjR5BYAzAC7NILG303Y9ME1EUyGEc0Q0hbU30Y6CiLJYW+hfCSF8o9O84+cNACGERSJ6AsDPARgmokznTbnTnpH3AfgoEX0YQAHAIIA/xM6eM4Ctf7P/EMDbOsplDsCvAfjmFs/hSvkmgPs6P98H4JFtnIuiYzd+CcCLIYTfv+RXO3beRDRBRMOdn/sAfBBrWsMTAD7R6baj5hxC+FwIYW8I4SDWnt+/DiH8OnbwnH9CCGFL/wH4MICXsWab/butPn6Pc/wqgHMAEqzZX/djzS57HMAJAN8BMLrd8xRz/nmsfUV/FsCxzr8P7+R5A/gZAD/qzPl5AP++034IwA8AnATw5wDy2z3Xdeb/AQCPXi9zdg86x0kJLtA5Tkrwxe44KcEXu+OkBF/sjpMSfLE7Tkrwxe44KcEXu+OkBF/sjpMS/j8Mfcbxf4TO1AAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFDTVBnJtiuj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "face_arr = np.asarray(face, dtype = np.float32)\n",
        "face_arr = face_arr / 255\n",
        "# face_arr\n",
        "face_arr.shape = (1, 48, 48, 1)\n",
        "\n",
        "# face.save(image_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hkm-KjH5uOPN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "0c032230-b92a-42f4-ebdb-03334e7fe1e6"
      },
      "source": [
        "pred_arr = Emodel.predict(face_arr, verbose = 1)\n",
        "pred_arr"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r1/1 [==============================] - 6s 6s/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.1619563 , 0.0019418 , 0.1443102 , 0.00653373, 0.12347215,\n",
              "        0.05256133, 0.5092245 ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5zfTwPM1CGz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "516fb38f-e4dd-48dc-804e-7ae5bd7d4ccb"
      },
      "source": [
        "print(np.argmax(pred_arr))\n",
        "\n",
        "print(y_classes[np.argmax(pred_arr)])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6\n",
            "Neutral\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}